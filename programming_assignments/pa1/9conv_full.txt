
Config:
Samples per class: 500
Model: conv9


Loading training and test sets...





Train_y shape: 
 (100000, 200)
Test_y shape: 
 (10000, 200)
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 31, 31, 64)        256       
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 33, 33, 64)        0         
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 31, 31, 128)       73856     
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         
_________________________________________________________________
batch_normalization_2 (Batch (None, 16, 16, 128)       512       
_________________________________________________________________
zero_padding2d_2 (ZeroPaddin (None, 18, 18, 128)       0         
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 16, 16, 256)       295168    
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 8, 8, 256)         0         
_________________________________________________________________
batch_normalization_3 (Batch (None, 8, 8, 256)         1024      
_________________________________________________________________
zero_padding2d_3 (ZeroPaddin (None, 10, 10, 256)       0         
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 8, 8, 512)         1180160   
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 4, 4, 512)         0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 4, 4, 512)         2048      
_________________________________________________________________
zero_padding2d_4 (ZeroPaddin (None, 6, 6, 512)         0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 4, 4, 1024)        4719616   
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 2, 2, 1024)        0         
_________________________________________________________________
batch_normalization_5 (Batch (None, 2, 2, 1024)        4096      
_________________________________________________________________
zero_padding2d_5 (ZeroPaddin (None, 4, 4, 1024)        0         
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 2, 2, 512)         4719104   
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 1, 1, 512)         0         
_________________________________________________________________
batch_normalization_6 (Batch (None, 1, 1, 512)         2048      
_________________________________________________________________
zero_padding2d_6 (ZeroPaddin (None, 3, 3, 512)         0         
_________________________________________________________________
conv2d_7 (Conv2D)            (None, 1, 1, 256)         1179904   
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 1, 1, 256)         0         
_________________________________________________________________
batch_normalization_7 (Batch (None, 1, 1, 256)         1024      
_________________________________________________________________
zero_padding2d_7 (ZeroPaddin (None, 3, 3, 256)         0         
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 1, 1, 128)         295040    
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 1, 1, 128)         0         
_________________________________________________________________
batch_normalization_8 (Batch (None, 1, 1, 128)         512       
_________________________________________________________________
zero_padding2d_8 (ZeroPaddin (None, 3, 3, 128)         0         
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 1, 1, 64)          73792     
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 1, 1, 64)          0         
_________________________________________________________________
batch_normalization_9 (Batch (None, 1, 1, 64)          256       
_________________________________________________________________
zero_padding2d_9 (ZeroPaddin (None, 3, 3, 64)          0         
_________________________________________________________________
flatten_1 (Flatten)          (None, 576)               0         
_________________________________________________________________
dense_1 (Dense)              (None, 512)               295424    
_________________________________________________________________
dense_2 (Dense)              (None, 200)               102600    
=================================================================
Total params: 12,948,232
Trainable params: 12,942,344
Non-trainable params: 5,888
_________________________________________________________________
None


9 Conv layer model
Train on 90000 samples, validate on 10000 samples
Epoch 1/15
 - 66s - loss: 4.5068 - accuracy: 0.0664 - val_loss: 4.5361 - val_accuracy: 0.0727
Epoch 2/15
 - 67s - loss: 3.8147 - accuracy: 0.1445 - val_loss: 3.7054 - val_accuracy: 0.1605
Epoch 3/15
 - 69s - loss: 3.4119 - accuracy: 0.2084 - val_loss: 3.3979 - val_accuracy: 0.2114
Epoch 4/15
 - 69s - loss: 3.0386 - accuracy: 0.2744 - val_loss: 3.4435 - val_accuracy: 0.2159
Epoch 5/15
 - 69s - loss: 2.6312 - accuracy: 0.3503 - val_loss: 3.1485 - val_accuracy: 0.2832
Epoch 6/15
 - 69s - loss: 2.1505 - accuracy: 0.4443 - val_loss: 3.0703 - val_accuracy: 0.3043
Epoch 7/15
 - 68s - loss: 1.6118 - accuracy: 0.5599 - val_loss: 3.4038 - val_accuracy: 0.2952
Epoch 8/15
 - 69s - loss: 1.1553 - accuracy: 0.6682 - val_loss: 3.7464 - val_accuracy: 0.3009
Epoch 9/15
 - 69s - loss: 0.8291 - accuracy: 0.7534 - val_loss: 4.2689 - val_accuracy: 0.2904
Epoch 10/15
 - 69s - loss: 0.6262 - accuracy: 0.8094 - val_loss: 4.5293 - val_accuracy: 0.3000
Epoch 11/15
 - 65s - loss: 0.4918 - accuracy: 0.8488 - val_loss: 4.9202 - val_accuracy: 0.2823
Epoch 12/15
 - 63s - loss: 0.4117 - accuracy: 0.8706 - val_loss: 5.1044 - val_accuracy: 0.2835
Epoch 13/15
 - 62s - loss: 0.3527 - accuracy: 0.8889 - val_loss: 5.3322 - val_accuracy: 0.2904
Epoch 14/15
 - 63s - loss: 0.3131 - accuracy: 0.9003 - val_loss: 5.5091 - val_accuracy: 0.2885
Epoch 15/15
 - 63s - loss: 0.2842 - accuracy: 0.9098 - val_loss: 5.7894 - val_accuracy: 0.2860


Total training time taken (mins:sec): 16:42.32



9 Conv Layer model predictions:


Predicting on test set...

   32/10000 [..............................] - ETA: 2:30
  288/10000 [..............................] - ETA: 18s 
  512/10000 [>.............................] - ETA: 11s
  704/10000 [=>............................] - ETA: 8s 
  896/10000 [=>............................] - ETA: 7s
 1088/10000 [==>...........................] - ETA: 6s
 1280/10000 [==>...........................] - ETA: 5s
 1472/10000 [===>..........................] - ETA: 4s
 1664/10000 [===>..........................] - ETA: 4s
 1856/10000 [====>.........................] - ETA: 4s
 2048/10000 [=====>........................] - ETA: 3s
 2240/10000 [=====>........................] - ETA: 3s
 2432/10000 [======>.......................] - ETA: 3s
 2624/10000 [======>.......................] - ETA: 3s
 2816/10000 [=======>......................] - ETA: 3s
 3008/10000 [========>.....................] - ETA: 3s
 3200/10000 [========>.....................] - ETA: 2s
 3392/10000 [=========>....................] - ETA: 2s
 3584/10000 [=========>....................] - ETA: 2s
 3776/10000 [==========>...................] - ETA: 2s
 3968/10000 [==========>...................] - ETA: 2s
 4160/10000 [===========>..................] - ETA: 2s
 4352/10000 [============>.................] - ETA: 2s
 4544/10000 [============>.................] - ETA: 2s
 4736/10000 [=============>................] - ETA: 1s
 4928/10000 [=============>................] - ETA: 1s
 5120/10000 [==============>...............] - ETA: 1s
 5312/10000 [==============>...............] - ETA: 1s
 5504/10000 [===============>..............] - ETA: 1s
 5696/10000 [================>.............] - ETA: 1s
 5888/10000 [================>.............] - ETA: 1s
 6080/10000 [=================>............] - ETA: 1s
 6272/10000 [=================>............] - ETA: 1s
 6464/10000 [==================>...........] - ETA: 1s
 6656/10000 [==================>...........] - ETA: 1s
 6880/10000 [===================>..........] - ETA: 1s
 7104/10000 [====================>.........] - ETA: 0s
 7328/10000 [====================>.........] - ETA: 0s
 7520/10000 [=====================>........] - ETA: 0s
 7712/10000 [======================>.......] - ETA: 0s
 7904/10000 [======================>.......] - ETA: 0s
 8096/10000 [=======================>......] - ETA: 0s
 8288/10000 [=======================>......] - ETA: 0s
 8512/10000 [========================>.....] - ETA: 0s
 8736/10000 [=========================>....] - ETA: 0s
 8928/10000 [=========================>....] - ETA: 0s
 9120/10000 [==========================>...] - ETA: 0s
 9312/10000 [==========================>...] - ETA: 0s
 9504/10000 [===========================>..] - ETA: 0s
 9696/10000 [============================>.] - ETA: 0s
 9888/10000 [============================>.] - ETA: 0s
10000/10000 [==============================] - 3s 326us/step

Predicted Class Indices: 

[ 71  64 127 ...  69 118  99]
Num predictions:  10000

Test set accuracy: 27.16%
